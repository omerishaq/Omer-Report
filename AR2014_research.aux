\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Research}{1}}
\newlabel{research}{{1}{1}}
\newlabel{research_proj}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  A slice from a volume image of a paper sample. (a) directly reconstructed, a mixed imaged with both phase and amplitude. (b) phase contribution removed to reveal the amplitude or absorption.}}{2}}
\newlabel{fig:diffraction}{{1}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{2}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Forestry related applications}{2}}
\newlabel{proj:paper}{{2}{2}}
\newlabel{proj:woodSynth}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Analysis of microscopic biomedical images}{5}}
\newlabel{proj:PVS2}{{5}{5}}
\newlabel{proj:PVS1}{{6}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Desk-top and mobile version of the miniTEM (left). Nanotubes, approximately 15nm thick, the first image acquired with the miniTEM (right).}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\newlabel{fig:miniTEM}{{2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Demonstrating the sensitivity of the sequencing method (finding rare mutants) - cell culture of ONCO-DG1 with wild type KRAS (GG) spiked with A549 cells (1:100) with mutant KRAS (AG). Note how the majority of the cells express the wild type gene (cyan), while a few express multiple copies of the mutated gene (pink).}}{7}}
\newlabel{fig:carolina_insitu}{{3}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  Vessel centerline tree extraction in a CT dataset containing lower part of the leg. For clarity the resulting centerline is dilated and marked by purple color. The manual segmentation is shown by yellow color. All main vessel and some additional false positive centerlines around the knee area have been detected.}}{9}}
\newlabel{fig:Skeleton}{{4}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces (a) Neural stem cells differentiating to astrocytes (red) and oligodendrocytes (green). Contours show segmented astrocytes and nuclei, using CellProfiler. Experiment by Tanja Paavilainen. (b) Cells from a glioma cell line expressing (blue marker) or not (orange marker) Oligodendrocyte transcription factor (OLIG2). Classifiaction obtained with CellProfiler Analyst. Experiment by Tobias Bergstr\"{o}m.}}{10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{10}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{10}}
\newlabel{fig::stem_cells}{{5}{10}}
\newlabel{proj:stemcells}{{12}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Slit-scanning confocal microscope image of the endothelium of a patient's cornea, with a manual marking used to determine cell density (red), and the result of our automated algorithm (green). The manual markings take about four minutes per image to do, whereas the algorithm finishes in less than half a minute and requires no interaction at all. The white bar indicates 100$\mskip \thickmuskip \mu $m. The image is a typical example (i.e. the one with the nicest segmentation result).}}{11}}
\newlabel{fig:cornea}{{6}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  The system developed in the CerviScan project will screen an entire specimen and within each field of view segment cervical cell nuclei that are visible. A series of structural and statistical measurements will then be acquired from these in order to determine if the specimen is normal or abnormal.}}{13}}
\newlabel{fig:cerviscan}{{7}{13}}
\newlabel{proj:cellsurfaceDiffusion}{{20}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A graph constructed on top of Gata-4 marked germ cells.}}{17}}
\newlabel{testis}{{8}{17}}
\newlabel{proj:CombatingCancer}{{23}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Results of color decomposition: (a) original tissue image stained with Sir-Htx, (b) stroma density map, and (c) epithelial density map; (d) original tissue image stained with H\&E, (e) stroma density map, and (f) nuclei density map. }}{18}}
\newlabel{fig:prostate2}{{9}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Epithelial nuclei identified by the marked point process. }}{20}}
\newlabel{fig:prostate3}{{10}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Example of a sub-section of a whole-mount tissue section with three individual scores. }}{21}}
\newlabel{fig:prostate4}{{11}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Steps for curvature extraction: (a) An input image; (b) After illumination correction; (c) Binary image after smoothing and thresholding; (d) Computed medial axes (highlighted in green) and seed-points (highlighted in red); (e) Refined medial axes (highlighted in yellow); (f) Medial axis fusion: the red lines represent tail-segments fused together to yield the complete tails (shown in yellow).}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {}}}{22}}
\newlabel{fig::zebrafish_curvature}{{12}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces  The image to the left is a maximum projection of the zebrafish image volume, and the image to the right shows the detected stationary lipids in red.}}{22}}
\newlabel{fig:hamid}{{13}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces (a) Recorded projection of a zebrafish embryo. (b) The projection after flat field correction. (c) Reconstructed frontal slice. (d) Volume rendering of the reconstructed image.}}{24}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{24}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{24}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{24}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{24}}
\newlabel{fig::tomography_fish}{{14}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces (a) Projection of a 3D cell culture. (b) Volume rendering of the reconstructed image.}}{24}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{24}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{24}}
\newlabel{fig::tomography_cell}{{15}{24}}
\newlabel{proj:gigapixel}{{29}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces  A description of the workflow.}}{26}}
\newlabel{fig:gigapixel}{{16}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}3D analysis and visualization}{27}}
\newlabel{proj:CMS}{{30}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces  CAD model of haptic gripper seen from the front (left) and back (right).The ultrasonic piezoelectric motors (A) actuate one DOF for the thumb (B) and one DOF for the remaining fingers (C). The connector (D) may be used to attach the gripper to a commercial six DOF haptic arm, for a total of eight DOF.}}{27}}
\newlabel{fig:haptic1}{{17}{27}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{27}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces  Example of possible mapping between physical and virtual tool: (a) all fingers straight - the virtual sculpting tool becomes a line segment; (b) middle and ring fingers bent - the curvature of the tool changes; (c) thumb bent - the width of the tool changes; (d) both sensors bent - simultaneous control of curvature and width.}}{28}}
\newlabel{fig:haptic2}{{18}{28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{28}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces  Design steps: (a) initialization of the deformable model (blue). Its growth is constrained by a bounding surface (transparent) and the defect surfaces; (b) model growing; (c) fine-tuning and generation of scaffold structure; (d) plate design.}}{29}}
\newlabel{fig:haptic3}{{19}{29}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces For searching an electron tomography image (left) with a molecular template, a standard, but powerful, method is to use a correlation search with a static template. With the ProViz software a 3-D fitness landscape (right), showing the correlation result at different points, can easily be calculated. The electron tomography image to the left is in this case synthetic for evaluation purposes.}}{31}}
\newlabel{fig::proviz}{{20}{31}}
\newlabel{proj:MRI_optimal_lattices}{{32}{31}}
\newlabel{proj:MRI_registration}{{33}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces  A screen-shot of the user interface of our software for interactive deformable registration. The target image and the transformed source image are displayed using a colored overlay in three orthogonal views. The user can deform the source image by clicking and dragging in any of the views, as shown in the screen-shot.}}{32}}
\newlabel{fig:interactive_image_registration}{{21}{32}}
\newlabel{project:medical_segmentation}{{34}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces  Screenshot from the \emph  {Smartpaint} software for interactive segmentation of volume images, developed at CBA. A radiologist segments the prostate in a MR image by interactively ``painting'' the segmentation using a brush tool.}}{33}}
\newlabel{fig:smartpaint}{{22}{33}}
\newlabel{project:orbit_segmentation}{{35}{33}}
\newlabel{project:wrist_angle_measurements}{{36}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Haptic-aided semi-automatic segmentation of the left orbit (eye-socket) in a post-operative CT scan of a patient suffering from Crouzon syndrom, a congenital disorder that makes the orbits smaller and more shallow than normal.}}{35}}
\newlabel{fig:orbit1}{{23}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Registration-based comparison of automatically constructed mean size and shape models of the orbit. In this case, a mean control model of normal orbits is compared against a mean model of pre-operative orbits from patients suffering from congenital disorder called Crouzon-Pfeiffer syndrome (CPS). The semi-transparent surface overlays and color-coded distance maps shows that CPS orbits tend to be smaller and more shallow than normal orbits.}}{36}}
\newlabel{fig:orbit2}{{24}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces  (a) The dorsal angle, $\theta $, measured in 2D on a lateral X-ray image of the radius bone in the wrist. $\theta $ is defined as the angle between the joint line JL and a line that is orthogonal to the long axis RA of the radius. (b) A 3D rendering of the radius bone and the reference axes we identify to measure the dorsal angle in 3D.}}{37}}
\newlabel{fig:wrist}{{25}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Theory: discrete geometry, mathematical morphology and volume processing}{39}}
\newlabel{project:interactive_segmentation}{{39}{39}}
\newlabel{proj:stochwatershed}{{40}{39}}
\newlabel{proj:DT}{{42}{40}}
\newlabel{proj:MBD}{{43}{41}}
\newlabel{proj:set_dist}{{44}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Other projects}{43}}
\newlabel{proj:geomemories}{{47}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces  This blended photo makes it possible to study how the costal shore line outside Pisa has changed and moved in time and space. Images from four different sources are blended together in the GeoMemories application to show the environmental changes. The images are a cadastral map that was published 1765, officially issued by Pietro Leopoldo the Grand Duke of Tuscany, a RAF photo from 1943, an aerial photo from 1962 and a recent Google Earth photo.}}{44}}
\newlabel{fig:pisa}{{26}{44}}
\newlabel{proj:honey_bees}{{50}{45}}
\newlabel{proj:fishslu}{{51}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces  Detecting adipose fin in salmon and sea trout.}}{47}}
\newlabel{fig:fishslu}{{27}{47}}
\newlabel{proj:dipimage}{{52}{47}}
